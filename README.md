# Flight Price Analysis Pipeline â€“ Bangladesh ðŸ‡§ðŸ‡©

An automated data pipeline built with Apache Airflow to analyze flight price data for flights originating from Bangladesh. This project extracts, transforms, loads, and analyzes synthetic flight data and computes key KPIs for decision-making.

---

## Tech Stack

- **Apache Airflow** (Orchestration)
- **MySQL** (Staging DB)
- **PostgreSQL** (Analytics DB)
- **Docker & Docker Compose** (Environment)
- **Python + Pandas** (Data processing)

---

## Project Structure

```
â”œâ”€â”€ dags/ # Airflow DAG definition
â”‚ â””â”€â”€ flight_price_pipeline.py
â”œâ”€â”€ scripts/ # Python logic for ETL
â”‚ â”œâ”€â”€ load_csv_to_mysql.py
â”‚ â”œâ”€â”€ validate_data.py
â”‚ â”œâ”€â”€ transform_data.py
â”‚ â”œâ”€â”€ compute_kpis.py
â”‚ â”œâ”€â”€ load_to_postgres.py
â”‚ â””â”€â”€ utils/
â”‚ â””â”€â”€ logger.py
â”œâ”€â”€ data/
â”‚ â””â”€â”€ Flight_Price_Dataset_of_Bangladesh.csv
â”œâ”€â”€ .env 
â”œâ”€â”€ docker-compose.yaml
â””â”€â”€ README.md
```
---

---
## DAG Overview: `flight_price_pipeline_Peter_Caleb_Ayertey`

| Task ID             | Description                                  |
|---------------------|----------------------------------------------|
| `load_csv_to_mysql` | Load CSV into MySQL staging DB               |
| `validate_data`     | Check for missing/invalid values             |
| `transform_data`    | Clean and normalize raw flight data          |
| `compute_kpis`      | Calculate KPIs: avg fare, route popularity   |
| `load_to_postgres`  | Load final KPIs into PostgreSQL analytics DB |

- **Schedule:** Every 3 hours (`0 */3 * * *`)
- **Catchup:** Disabled
- **Retries:** 2 (1-minute delay)

---

## KPI Metrics Computed

- **Average Fare by Airline**
- **Seasonal Fare Variation** (Eid, Hajj, Winter, Regular)
- **Booking Count by Airline**
- **Most Popular Routes** (Top Source-Destination pairs)

---

## Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/ayertey1/GTP_DE-Projects.git
cd flight-price-pipeline
```

### 2. Create your `.env` file

### 3. Start everything with Docker
```bash
docker-compose up -d
```
### 4. create admin user for Airflow UI
```powershell
docker exec -it airflowproject-webserver-1 airflow users create --username admin --firstname Admin --lastname User --role Admin --email peter.ayertey@amalitechtraining.org --password admin123
```

## Testing the Pipeline
* Go to http://localhost:8080

* Login with:

    Username: admin

    Password: admin123

* Turn on the DAG toggle

* Wait for a scheduled run (every 3 hours) or click â–¶ Trigger DAG

## Alerts
Logs are visible in the Airflow UI or directly inside container:
/opt/airflow/logs/...